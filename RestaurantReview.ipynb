{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Restaurant Reviews Clustering\r\n",
    "    In this project, we will use Natural Language Processing techniques and unsupervised learning \r\n",
    "    models to cluster restaurant reviews."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Data Collection\r\n",
    "    Data source: https://www.kaggle.com/d4rklucif3r/restaurant-reviews"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import nltk\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "nltk.download('punkt')\r\n",
    "nltk.download('stopwords')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dante\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dante\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load data\r\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\dante\\\\Desktop\\\\DS Project\\\\Restaurant Review\\\\Restaurant_Reviews.tsv\", sep = '\\t')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Take a peek\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  1000 non-null   object\n",
      " 1   Liked   1000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "    Small dataset, no missing value. We're doing clustering instead of prediction, so did not \r\n",
    "    check 'Liked' column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data = df.loc[:, 'Review']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data Preprocessing\r\n",
    "    Tokenization dan stemming"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english') \r\n",
    "stopwords.append(\"'m\")\r\n",
    "stopwords.append(\"'s\")\r\n",
    "stopwords.remove('not')\r\n",
    "stopwords.remove('no')\r\n",
    "\r\n",
    "print('We use ' + str(len(stopwords)) + ' stop-words fron nltk library.')\r\n",
    "print(stopwords)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "We use 179 stop-words fron nltk library.\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", \"'m\", \"'s\"]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\r\n",
    "# from nltk.stem import WordNetLemmatizer\r\n",
    "\r\n",
    "stemmer = SnowballStemmer(\"english\")\r\n",
    "\r\n",
    "# Define a function to do Tokenization and stemming\r\n",
    "def tokenization_and_stemming(text):\r\n",
    "    \r\n",
    "    # exclude stopwords and tokenize the document, generate a list of string\r\n",
    "    tokens = []\r\n",
    "    for word in nltk.word_tokenize(text):\r\n",
    "        if word.lower() not in stopwords:\r\n",
    "            tokens.append(word.lower())    \r\n",
    "\r\n",
    "    # filter out any tokens not containing letters (eg. numeric tokens, raw punctuations)\r\n",
    "    filtered_tokens = []\r\n",
    "    for token in tokens:\r\n",
    "        if token.isalpha():\r\n",
    "            filtered_tokens.append(token)\r\n",
    "\r\n",
    "    # stemming\r\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\r\n",
    "\r\n",
    "    return stems"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "tokenization_and_stemming(data[13])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['tri', 'cape', 'cod', 'ravoli', 'chicken', 'cranberri', 'mmmm']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "data[13]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'I tried the Cape Cod ravoli, chicken, with cranberry...mmmm!'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "    Seems to be working!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. TF-IDF\r\n",
    "    Term Frequency Inverse Document Frequency"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "tfidf_model = TfidfVectorizer(max_df = 0.997, max_features = 1000, min_df = 0.003,\\\r\n",
    "    stop_words = 'english', use_idf = True, tokenizer = tokenization_and_stemming,\\\r\n",
    "    ngram_range = (1,2))\r\n",
    "\r\n",
    "tfidf_matrix = tfidf_model.fit_transform(data) # fit the vectorizer to synopses\r\n",
    "\r\n",
    "print('In total, there are ' + str(tfidf_matrix.shape[0]) + ' reviews and ' + \\\r\n",
    "    str(tfidf_matrix.shape[1]) + ' terms.')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In total, there are 1000 reviews and 478 terms.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\dante\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afterward', 'alon', 'alreadi', 'alway', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becom', 'besid', 'cri', 'describ', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'otherwis', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Key terms:\r\n",
    "tf_selected_words = tfidf_model.get_feature_names()\r\n",
    "tf_selected_words[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['absolut',\n",
       " 'actual',\n",
       " 'ago',\n",
       " 'alway',\n",
       " 'amaz',\n",
       " 'ambianc',\n",
       " 'ambienc',\n",
       " 'anoth',\n",
       " 'anoth minut',\n",
       " 'anytim']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Clustering Modeling\r\n",
    "    K-Means"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from sklearn.cluster import KMeans\r\n",
    "\r\n",
    "# number of clusters\r\n",
    "num_clusters = 3\r\n",
    "\r\n",
    "km = KMeans(n_clusters = num_clusters)\r\n",
    "km.fit(tfidf_matrix)\r\n",
    "\r\n",
    "clusters = km.labels_.tolist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clustering Results:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "product = {'Review': df.Review, 'Cluster': clusters}\r\n",
    "frame = pd.DataFrame(product, columns = ['Review', 'Cluster'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "frame.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              Review  Cluster\n",
       "0                           Wow... Loved this place.        0\n",
       "1                                 Crust is not good.        2\n",
       "2          Not tasty and the texture was just nasty.        0\n",
       "3  Stopped by during the late May bank holiday of...        0\n",
       "4  The selection on the menu was great and so wer...        1\n",
       "5     Now I am getting angry and I want my damn pho.        0\n",
       "6              Honeslty it didn't taste THAT fresh.)        0\n",
       "7  The potatoes were like rubber and you could te...        0\n",
       "8                          The fries were great too.        1\n",
       "9                                     A great touch.        1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The potatoes were like rubber and you could te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The fries were great too.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A great touch.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Count in each subgroup:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "result = pd.merge(frame, df, left_index= True, right_index=True)\r\n",
    "result = result.loc[:, ['Cluster', 'Liked']]\r\n",
    "result.groupby(['Cluster','Liked']).size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Cluster  Liked\n",
       "0        0        445\n",
       "         1        349\n",
       "1        0         36\n",
       "         1         84\n",
       "2        0         19\n",
       "         1         67\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "    Looks like the majority of reviewers in Cluster 2 also 'liked' the restaurant. \r\n",
    "    While in other two clusters the reviews are more mixed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### keywords in each cluster:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print(\"<Document clustering result by K-means>\")\r\n",
    "\r\n",
    "# km.cluster_centers_ denotes the importances of each items in centroid\r\n",
    "# we need to sort it in decresing-order and get the top k items.\r\n",
    "\r\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\r\n",
    "\r\n",
    "Cluster_keywords_summary = {}\r\n",
    "for i in range(num_clusters):\r\n",
    "    print('Cluster ' + str(i) + ' keywords: ', end = '')\r\n",
    "    Cluster_keywords_summary[i] = []\r\n",
    "    for ind in order_centroids[i, :10]: # top 6 items\r\n",
    "        Cluster_keywords_summary[i].append(tf_selected_words[ind])\r\n",
    "        print(tf_selected_words[ind] + ',', end = '')\r\n",
    "    print()    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<Document clustering result by K-means>\n",
      "Cluster 0 keywords: place,food,like,time,disappoint,love,delici,amaz,wo,eat,\n",
      "Cluster 1 keywords: servic,great,food,slow,friend,great food,great place,terribl,place,great servic,\n",
      "Cluster 2 keywords: good,food,food good,good food,realli,realli good,pizza,servic,select,place,\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "    The clustering seems OK. Admittedly it looks a little hectic: mixed good and bad in cluster \r\n",
    "    0 and 1. Cluster 2 seems to agree on the good side. This result agrees with the previous\r\n",
    "    count in each subgroup. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Topic Modeling\r\n",
    "    Latent Dirichlet Allocation (LDA)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\r\n",
    "lda = LatentDirichletAllocation(n_components = 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Document topic matrix for tfidf_matrix_lda\r\n",
    "lda_output = lda.fit_transform(tfidf_matrix)\r\n",
    "print(lda_output.shape)\r\n",
    "print(lda_output)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1000, 3)\n",
      "[[0.11527425 0.13915242 0.74557332]\n",
      " [0.16767929 0.16961207 0.66270864]\n",
      " [0.56105358 0.31582987 0.12311655]\n",
      " ...\n",
      " [0.13860161 0.43352276 0.42787563]\n",
      " [0.45975244 0.14040976 0.3998378 ]\n",
      " [0.09811508 0.80372664 0.09815827]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Topic and word matrix\r\n",
    "topic_word = lda.components_\r\n",
    "print(topic_word.shape)\r\n",
    "print(topic_word)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3, 478)\n",
      "[[0.34551523 0.37313292 0.33493329 ... 0.33838505 0.33516836 0.33529299]\n",
      " [0.34412442 1.86540414 0.34924409 ... 0.35064214 0.33484736 0.33493246]\n",
      " [5.14011999 0.35114393 1.61580988 ... 2.48582499 2.38981853 2.03093862]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Column names\r\n",
    "topic_names = ['Topic' + str(i) for i in range(lda.n_components)]\r\n",
    "\r\n",
    "# Index names\r\n",
    "doc_names = ['Doc' + str(i) for i in range(len(data))]\r\n",
    "\r\n",
    "# Creating document topic matrix\r\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns = topic_names, \\\r\n",
    "    index = doc_names)\r\n",
    "\r\n",
    "# Get dominant topic for each document\r\n",
    "topic = np.argmax(df_document_topic.values, axis = 1)\r\n",
    "df_document_topic['Topic'] = topic\r\n",
    "\r\n",
    "# Document topic matrix\r\n",
    "df_document_topic.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Topic0  Topic1  Topic2  Topic\n",
       "Doc0    0.12    0.14    0.75      2\n",
       "Doc1    0.17    0.17    0.66      2\n",
       "Doc2    0.56    0.32    0.12      0\n",
       "Doc3    0.12    0.15    0.72      2\n",
       "Doc4    0.32    0.28    0.39      2\n",
       "Doc5    0.67    0.19    0.14      0\n",
       "Doc6    0.72    0.14    0.14      0\n",
       "Doc7    0.77    0.12    0.11      0\n",
       "Doc8    0.65    0.14    0.21      0\n",
       "Doc9    0.14    0.14    0.71      2"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.66</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.72</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc5</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc6</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc7</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc8</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc9</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Counts:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "df_newidx = df.copy()\r\n",
    "df_newidx.index = doc_names\r\n",
    "\r\n",
    "result_LDA = pd.merge(df_document_topic, df_newidx, left_index = True, right_index = True)\r\n",
    "\r\n",
    "result_LDA[['Topic','Liked']].groupby(['Topic','Liked']).size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Topic  Liked\n",
       "0      0        186\n",
       "       1        130\n",
       "1      0        168\n",
       "       1        149\n",
       "2      0        146\n",
       "       1        221\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "    LDA clustered pretty evenly. However, among three topics, there appear to be no difference \r\n",
    "    in proportion of 'Liked' reviews."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Topic word matrix\r\n",
    "print(lda.components_)\r\n",
    "\r\n",
    "# Create DF\r\n",
    "df_topic_words = pd.DataFrame(lda.components_)\r\n",
    "\r\n",
    "# Column and index name\r\n",
    "df_topic_words.columns = tfidf_model.get_feature_names()\r\n",
    "df_topic_words.index = topic_names\r\n",
    "\r\n",
    "df_topic_words.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.34551523 0.37313292 0.33493329 ... 0.33838505 0.33516836 0.33529299]\n",
      " [0.34412442 1.86540414 0.34924409 ... 0.35064214 0.33484736 0.33493246]\n",
      " [5.14011999 0.35114393 1.61580988 ... 2.48582499 2.38981853 2.03093862]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         absolut    actual       ago     alway      amaz   ambianc   ambienc  \\\n",
       "Topic0  0.345515  0.373133  0.334933  0.361120  5.131986  0.382933  0.346009   \n",
       "Topic1  0.344124  1.865404  0.349244  0.349561  0.385349  0.335882  2.114312   \n",
       "Topic2  5.140120  0.351144  1.615810  7.020998  8.153946  4.400497  0.335103   \n",
       "\n",
       "           anoth  anoth minut    anytim  ...     worst     worth       wow  \\\n",
       "Topic0  0.338053     0.334502  0.339801  ...  9.192484  3.096285  0.336556   \n",
       "Topic1  4.105665     2.098040  0.334766  ...  0.341849  0.353203  1.617888   \n",
       "Topic2  0.354371     0.337670  2.863410  ...  0.339355  2.547201  0.894719   \n",
       "\n",
       "            wrap     wrong      year  year ago     yummi      zero  zero star  \n",
       "Topic0  0.551994  0.337099  0.726343  0.334933  0.338385  0.335168   0.335293  \n",
       "Topic1  0.338248  2.844924  0.346953  0.349244  0.350642  0.334847   0.334932  \n",
       "Topic2  1.507720  0.691146  2.096470  1.615810  2.485825  2.389819   2.030939  \n",
       "\n",
       "[3 rows x 478 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolut</th>\n",
       "      <th>actual</th>\n",
       "      <th>ago</th>\n",
       "      <th>alway</th>\n",
       "      <th>amaz</th>\n",
       "      <th>ambianc</th>\n",
       "      <th>ambienc</th>\n",
       "      <th>anoth</th>\n",
       "      <th>anoth minut</th>\n",
       "      <th>anytim</th>\n",
       "      <th>...</th>\n",
       "      <th>worst</th>\n",
       "      <th>worth</th>\n",
       "      <th>wow</th>\n",
       "      <th>wrap</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>year ago</th>\n",
       "      <th>yummi</th>\n",
       "      <th>zero</th>\n",
       "      <th>zero star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic0</th>\n",
       "      <td>0.345515</td>\n",
       "      <td>0.373133</td>\n",
       "      <td>0.334933</td>\n",
       "      <td>0.361120</td>\n",
       "      <td>5.131986</td>\n",
       "      <td>0.382933</td>\n",
       "      <td>0.346009</td>\n",
       "      <td>0.338053</td>\n",
       "      <td>0.334502</td>\n",
       "      <td>0.339801</td>\n",
       "      <td>...</td>\n",
       "      <td>9.192484</td>\n",
       "      <td>3.096285</td>\n",
       "      <td>0.336556</td>\n",
       "      <td>0.551994</td>\n",
       "      <td>0.337099</td>\n",
       "      <td>0.726343</td>\n",
       "      <td>0.334933</td>\n",
       "      <td>0.338385</td>\n",
       "      <td>0.335168</td>\n",
       "      <td>0.335293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>0.344124</td>\n",
       "      <td>1.865404</td>\n",
       "      <td>0.349244</td>\n",
       "      <td>0.349561</td>\n",
       "      <td>0.385349</td>\n",
       "      <td>0.335882</td>\n",
       "      <td>2.114312</td>\n",
       "      <td>4.105665</td>\n",
       "      <td>2.098040</td>\n",
       "      <td>0.334766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341849</td>\n",
       "      <td>0.353203</td>\n",
       "      <td>1.617888</td>\n",
       "      <td>0.338248</td>\n",
       "      <td>2.844924</td>\n",
       "      <td>0.346953</td>\n",
       "      <td>0.349244</td>\n",
       "      <td>0.350642</td>\n",
       "      <td>0.334847</td>\n",
       "      <td>0.334932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>5.140120</td>\n",
       "      <td>0.351144</td>\n",
       "      <td>1.615810</td>\n",
       "      <td>7.020998</td>\n",
       "      <td>8.153946</td>\n",
       "      <td>4.400497</td>\n",
       "      <td>0.335103</td>\n",
       "      <td>0.354371</td>\n",
       "      <td>0.337670</td>\n",
       "      <td>2.863410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339355</td>\n",
       "      <td>2.547201</td>\n",
       "      <td>0.894719</td>\n",
       "      <td>1.507720</td>\n",
       "      <td>0.691146</td>\n",
       "      <td>2.096470</td>\n",
       "      <td>1.615810</td>\n",
       "      <td>2.485825</td>\n",
       "      <td>2.389819</td>\n",
       "      <td>2.030939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 478 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### keywords:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def print_topic_words(tfidf_model, lda_model, n_words):\r\n",
    "    words = np.array(tfidf_model.get_feature_names())\r\n",
    "    topic_words = []\r\n",
    "    # for each topic, we have words weight\r\n",
    "    for topic_words_weights in lda_model.components_:\r\n",
    "        top_words = topic_words_weights.argsort()[::-1][:n_words]\r\n",
    "        topic_words.append(words.take(top_words))\r\n",
    "    return topic_words\r\n",
    "\r\n",
    "topic_keywords = print_topic_words(tfidf_model=tfidf_model, lda_model=lda, n_words=15)        \r\n",
    "\r\n",
    "df_topic_words = pd.DataFrame(topic_keywords)\r\n",
    "df_topic_words.columns = ['Word '+str(i+1) for i in range(df_topic_words.shape[1])]\r\n",
    "df_topic_words.index = ['Topic '+str(i+1) for i in range(df_topic_words.shape[0])]\r\n",
    "df_topic_words"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Word 1      Word 2  Word 3   Word 4  Word 5  Word 6   Word 7  Word 8  \\\n",
       "Topic 1    like  disappoint     eat       wo    best  friend    worst     bad   \n",
       "Topic 2  delici        time    come  definit  servic   price     food    vega   \n",
       "Topic 3    good       place  servic     food   great    love  restaur  realli   \n",
       "\n",
       "        Word 9 Word 10  Word 11 Word 12  Word 13  Word 14  Word 15  \n",
       "Topic 1  place   staff      fri    food   burger  probabl    fresh  \n",
       "Topic 2   came   steak   pretti     got  perfect    minut  terribl  \n",
       "Topic 3   wait   pizza  fantast    amaz      way   awesom    alway  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "      <th>Word 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>like</td>\n",
       "      <td>disappoint</td>\n",
       "      <td>eat</td>\n",
       "      <td>wo</td>\n",
       "      <td>best</td>\n",
       "      <td>friend</td>\n",
       "      <td>worst</td>\n",
       "      <td>bad</td>\n",
       "      <td>place</td>\n",
       "      <td>staff</td>\n",
       "      <td>fri</td>\n",
       "      <td>food</td>\n",
       "      <td>burger</td>\n",
       "      <td>probabl</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>delici</td>\n",
       "      <td>time</td>\n",
       "      <td>come</td>\n",
       "      <td>definit</td>\n",
       "      <td>servic</td>\n",
       "      <td>price</td>\n",
       "      <td>food</td>\n",
       "      <td>vega</td>\n",
       "      <td>came</td>\n",
       "      <td>steak</td>\n",
       "      <td>pretti</td>\n",
       "      <td>got</td>\n",
       "      <td>perfect</td>\n",
       "      <td>minut</td>\n",
       "      <td>terribl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>good</td>\n",
       "      <td>place</td>\n",
       "      <td>servic</td>\n",
       "      <td>food</td>\n",
       "      <td>great</td>\n",
       "      <td>love</td>\n",
       "      <td>restaur</td>\n",
       "      <td>realli</td>\n",
       "      <td>wait</td>\n",
       "      <td>pizza</td>\n",
       "      <td>fantast</td>\n",
       "      <td>amaz</td>\n",
       "      <td>way</td>\n",
       "      <td>awesom</td>\n",
       "      <td>alway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "    Although the clustering is more even using LDA, it seems more ambiguous. We have \r\n",
    "    'good' and 'disappoint' in Topic 1, 'worst' right next to 'best' in Topic 2. This\r\n",
    "    result again agrees with the count in each group. However, I'm not sure how to use \r\n",
    "    this information. \r\n",
    "\r\n",
    "    Maybe in the future I will try to use supervised machine learning on this data given \r\n",
    "    there is the 'liked' column and see what I can do with a prediction model."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "fe44fef87f92f48a3a32707d0df204585f471652bc0ce87358a3ce712bc24db0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}